{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Databricks Exports (.dbc) to Python Scripts (.py) & IPython Notebooks (.ipynb)\n",
    "\n",
    "To download .dbc file from Databricks, click on the down arrow next to the root folder then hover the mouse over \"Export\" and click on \"DBC Archive\" or a single file can be exported by clicking on the down arrow next to the file, hovering the mouse over \"Export\", and clicking on \"DBC Archive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this fileLocation using proper syntax with '/'\n",
    "fileLocation = '.dbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Contents from the .dbc file (usually one file or a directory) ***\n",
      "\n",
      "['Spark Essentials']\n"
     ]
    }
   ],
   "source": [
    "# Extract dbc file\n",
    "\n",
    "# Cleanup from prior run\n",
    "import shutil\n",
    "try: shutil.rmtree('tmp_dbc')\n",
    "except OSError: pass\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "try: os.mkdir('tmp_dbc')\n",
    "except OSError: pass\n",
    "with zipfile.ZipFile(fileLocation, 'r') as z:\n",
    "    z.extractall('tmp_dbc')\n",
    "\n",
    "print('*** Contents from the .dbc file ***\\n')\n",
    "print(os.listdir('tmp_dbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Files to be created (relative to your current working directory) ***\n",
      "(Warning: files will be overwritten!)\n",
      "\n",
      ".\\1.6 Introduction to Notebooks_export.ipynb\n",
      ".\\2.2 Working with Text Files_export.ipynb\n",
      ".\\2.3 Loading CSV Data into DataFrames_export.ipynb\n",
      ".\\2.4 Exploring Data in DataFrames_export.ipynb\n",
      ".\\2.5 Saving Your Results_export.ipynb\n",
      ".\\4.2 Preparing Data for Machine Learning_export.ipynb\n",
      ".\\4.3 Building a Linear Regression Model_export.ipynb\n",
      ".\\4.4 Evaluating a Linear Regression Model_export.ipynb\n",
      ".\\4.5 Visualizing a Linear Regression Model_export.ipynb\n",
      ".\\5.2 Setting up Streaming Context_export.ipynb\n",
      ".\\5.3 Querying Streaming Data_export.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Find files to parse\n",
    "import fnmatch\n",
    "\n",
    "filesToParse = []\n",
    "for root, dirNames, fileNames in os.walk('tmp_dbc'):\n",
    "    for fileName in fnmatch.filter(fileNames, '*.python'):\n",
    "        filesToParse.append((root, fileName))\n",
    "\n",
    "def getIpynbName(path, fileName):\n",
    "    path = os.path.normpath(path)\n",
    "    pathSplit = path.split(os.sep)[2:]\n",
    "    baseDir = os.path.join(*pathSplit) if len(pathSplit) > 0 else '.'\n",
    "    newFileName = os.path.splitext(fileName)[0] + '_export.ipynb'\n",
    "    return os.path.join(baseDir, newFileName)\n",
    "\n",
    "print(\"*** Files to be created (relative to the current working directory) ***\")\n",
    "print(\"(Warning: files will be overwritten!)\\n\")\n",
    "for path, fileName in filesToParse:\n",
    "    print(getIpynbName(path, fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: .\\1.6 Introduction to Notebooks_export.ipynb\n",
      "Created: .\\2.2 Working with Text Files_export.ipynb\n",
      "Created: .\\2.3 Loading CSV Data into DataFrames_export.ipynb\n",
      "Created: .\\2.4 Exploring Data in DataFrames_export.ipynb\n",
      "Created: .\\2.5 Saving Your Results_export.ipynb\n",
      "Created: .\\4.2 Preparing Data for Machine Learning_export.ipynb\n",
      "Created: .\\4.3 Building a Linear Regression Model_export.ipynb\n",
      "Created: .\\4.4 Evaluating a Linear Regression Model_export.ipynb\n",
      "Created: .\\4.5 Visualizing a Linear Regression Model_export.ipynb\n",
      "Created: .\\5.2 Setting up Streaming Context_export.ipynb\n",
      "Created: .\\5.3 Querying Streaming Data_export.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Create the IPython Notebooks\n",
    "# Convert .python files to .ipynb files\n",
    "import codecs\n",
    "import nbformat\n",
    "from nbformat.v3.nbpy import PyReader\n",
    "import json\n",
    "import re\n",
    "\n",
    "_header = u'# -*- coding: utf-8 -*-\\n# <nbformat>3.0</nbformat>\\n'\n",
    "_markdownCell = u'\\n\\n# <markdowncell>\\n\\n'\n",
    "_codeCell = u'\\n\\n# <codecell>\\n\\n'\n",
    "_firstCell = u\"\"\"# Increase compatibility with Databricks\n",
    "from IPython.display import display as idisplay, HTML\n",
    "displayHTML = lambda x: idisplay(HTML(x))\n",
    "def display(*args, **kargs): pass\"\"\"\n",
    "\n",
    "def convertToIpynb(fileToParse):\n",
    "    \n",
    "    with codecs.open(os.path.join(*fileToParse), encoding=\"utf-8\") as fp:\n",
    "        jsonData = json.load(fp)\n",
    "        commands = jsonData['commands']\n",
    "        commandInfo = [(x['position'], x['command']) for x in commands]\n",
    "        commandList = sorted(commandInfo)\n",
    "\n",
    "    with codecs.open('tmp_ipynb.py', 'w', encoding=\"utf-8\") as fp:\n",
    "        fp.write(_header)\n",
    "        fp.write(_codeCell)\n",
    "        fp.write(_firstCell)\n",
    "\n",
    "        for position, command in commandList:\n",
    "            if re.match(r'\\s*%md', command):\n",
    "                command = re.sub(r'^\\s*%md', '', command, flags=re.MULTILINE)\n",
    "                command = re.sub(r'(%\\(|\\)%)', '$', command)\n",
    "                command = re.sub(r'(%\\[|\\]%)', '$$', command)\n",
    "\n",
    "                fp.write(_markdownCell)\n",
    "                asLines = command.split('\\n')\n",
    "                command = '# ' + '\\n# '.join(asLines)\n",
    "            else:\n",
    "                command = re.sub(r'^\\s*baseDir\\s*=.*$', 'baseDir = \\'data\\'', \n",
    "                                 command, flags=re.MULTILINE)\n",
    "                fp.write(_codeCell)\n",
    "\n",
    "            fp.write(command)\n",
    "\n",
    "    outputName = getIpynbName(fileToParse[0], fileToParse[1])\n",
    "\n",
    "    with codecs.open('tmp_ipynb.py', 'r', encoding=\"utf-8\") as intermediate:\n",
    "        nb = PyReader().read(intermediate)\n",
    "\n",
    "    os.remove('tmp_ipynb.py')\n",
    "    baseDirectory = os.path.split(outputName)[0]\n",
    "\n",
    "    if not os.path.isdir(baseDirectory):\n",
    "        os.makedirs(baseDirectory)\n",
    "\n",
    "    with codecs.open(outputName, 'w', encoding=\"utf-8\") as output:\n",
    "        nbformat.write(nbformat.convert(nb, 4.0), output)  \n",
    "        print('Created: {0}'.format(outputName))\n",
    "\n",
    "for fileToParse in filesToParse:\n",
    "    convertToIpynb(fileToParse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "try: shutil.rmtree('tmp_dbc')\n",
    "except OSError: pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
