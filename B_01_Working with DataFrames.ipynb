{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Notepad to myself --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic DataFrames Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_path + \"location_temp.csv\"\n",
    "df1 = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_date: string (nullable = true)\n",
      " |-- location_id: string (nullable = true)\n",
      " |-- temp_celcius: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|event_date         |location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|loc0       |29          |\n",
      "|03/04/2019 19:53:06|loc0       |27          |\n",
      "|03/04/2019 19:58:06|loc0       |28          |\n",
      "|03/04/2019 20:03:06|loc0       |30          |\n",
      "|03/04/2019 20:08:06|loc0       |27          |\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+------------------+\n",
      "|summary|         event_date|location_id|      temp_celcius|\n",
      "+-------+-------------------+-----------+------------------+\n",
      "|  count|             500000|     500000|            500000|\n",
      "|   mean|               null|       null|         28.065484|\n",
      "| stddev|               null|       null|3.8101229481235555|\n",
      "|    min|03/04/2019 19:48:06|       loc0|                21|\n",
      "|    max|03/08/2019 07:04:55|      loc99|                40|\n",
      "+-------+-------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_no_header = data_path + \"utilization.csv\"\n",
    "df2 = spark.read.csv(df2_no_header, header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----+----+---+\n",
      "|_c0                |_c1|_c2 |_c3 |_c4|\n",
      "+-------------------+---+----+----+---+\n",
      "|03/05/2019 08:06:14|100|0.57|0.51|47 |\n",
      "|03/05/2019 08:11:14|100|0.47|0.62|43 |\n",
      "|03/05/2019 08:16:14|100|0.56|0.57|62 |\n",
      "|03/05/2019 08:21:14|100|0.57|0.56|50 |\n",
      "|03/05/2019 08:26:14|100|0.35|0.46|43 |\n",
      "+-------------------+---+----+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"_c0\", \"event_datetime\") \\\n",
    "    .withColumnRenamed (\"_c1\", \"server_id\") \\\n",
    "    .withColumnRenamed(\"_c2\", \"cpu_utilization\") \\\n",
    "    .withColumnRenamed(\"_c3\", \"free_memory\") \\\n",
    "    .withColumnRenamed(\"_c4\", \"session_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_datetime: string (nullable = true)\n",
      " |-- server_id: integer (nullable = true)\n",
      " |-- cpu_utilization: double (nullable = true)\n",
      " |-- free_memory: double (nullable = true)\n",
      " |-- session_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|    cpu_utilization|     event_datetime|       free_memory|         server_id|     session_count|\n",
      "+-------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|             500000|             500000|            500000|            500000|            500000|\n",
      "|   mean| 0.6205177400000123|               null|0.3791280999999977|             124.5|          69.59616|\n",
      "| stddev|0.15875173872912837|               null|0.1583093127837622|14.430884120553253|14.850676696352865|\n",
      "|    min|               0.22|03/05/2019 08:06:14|               0.0|               100|                32|\n",
      "|    max|                1.0|04/09/2019 01:22:46|              0.78|               149|               105|\n",
      "+-------+-------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|event_datetime     |server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|100      |0.57           |0.51       |47           |\n",
      "|03/05/2019 08:11:14|100      |0.47           |0.62       |43           |\n",
      "|03/05/2019 08:16:14|100      |0.56           |0.57       |62           |\n",
      "|03/05/2019 08:21:14|100      |0.57           |0.56       |50           |\n",
      "|03/05/2019 08:26:14|100      |0.35           |0.46       |43           |\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write and Read json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write df1 as json\n",
    "df1_json = data_path + \"location_temp.json\"\n",
    "df1.write.json(df1_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write df2 as json\n",
    "df2_json = data_path + \"utilization.json\"\n",
    "df2.write.json(df2_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read json file\n",
    "df2_json_path = data_path + \"utilization.json\"\n",
    "df2 = spark.read.json(df2_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu_utilization',\n",
       " 'event_datetime',\n",
       " 'free_memory',\n",
       " 'server_id',\n",
       " 'session_count']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_sample = df2.sample(False, fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49877"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|   cpu_utilization|     event_datetime|        free_memory|         server_id|     session_count|\n",
      "+-------+------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             49877|              49877|              49877|             49877|             49877|\n",
      "|   mean|0.6218393247388593|               null|0.37813541311626636|124.48850171421698| 69.68624817049943|\n",
      "| stddev|0.1590928260944207|               null|0.15815794139331793|14.454386106764167|14.894331401576759|\n",
      "|    min|              0.22|03/05/2019 08:06:43|                0.0|               100|                32|\n",
      "|    max|               1.0|04/09/2019 01:22:09|               0.78|               149|               105|\n",
      "+-------+------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sample.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|event_datetime     |free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|0.71           |03/05/2019 08:06:43|0.61       |117      |60           |\n",
      "|0.78           |03/05/2019 08:06:45|0.45       |118      |68           |\n",
      "|0.51           |03/05/2019 08:06:46|0.49       |119      |53           |\n",
      "|0.64           |03/05/2019 08:06:51|0.48       |122      |65           |\n",
      "|0.52           |03/05/2019 08:07:06|0.49       |130      |77           |\n",
      "|0.5            |03/05/2019 08:07:09|0.49       |132      |65           |\n",
      "|0.39           |03/05/2019 08:07:39|0.63       |147      |49           |\n",
      "|0.59           |03/05/2019 08:11:17|0.13       |102      |70           |\n",
      "|0.62           |03/05/2019 08:12:09|0.63       |132      |59           |\n",
      "|0.95           |03/05/2019 08:12:12|0.28       |133      |90           |\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_sample.sort('event_datetime').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering using DataFrames API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|event_date         |location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|loc0       |29          |\n",
      "|03/04/2019 19:53:06|loc0       |27          |\n",
      "|03/04/2019 19:58:06|loc0       |28          |\n",
      "|03/04/2019 20:03:06|loc0       |30          |\n",
      "|03/04/2019 20:08:06|loc0       |27          |\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|event_date         |location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|loc1       |31          |\n",
      "|03/04/2019 19:53:06|loc1       |26          |\n",
      "|03/04/2019 19:58:06|loc1       |31          |\n",
      "|03/04/2019 20:03:06|loc1       |26          |\n",
      "|03/04/2019 20:08:06|loc1       |28          |\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"] == \"loc1\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|event_date         |location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|loc1       |31          |\n",
      "|03/04/2019 19:53:06|loc1       |26          |\n",
      "|03/04/2019 19:58:06|loc1       |31          |\n",
      "|03/04/2019 20:03:06|loc1       |26          |\n",
      "|03/04/2019 20:08:06|loc1       |28          |\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(\"location_id = 'loc1'\").show(5, truncate=False) #alternative usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"] == \"loc1\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating using DataFrames API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|      loc22| 1000|\n",
      "|      loc31| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|event_date         |location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 20:08:06|loc0       |27          |\n",
      "|03/04/2019 19:58:06|loc0       |28          |\n",
      "|03/04/2019 20:03:06|loc0       |30          |\n",
      "|03/04/2019 19:48:06|loc0       |29          |\n",
      "|03/04/2019 19:53:06|loc0       |27          |\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy(\"location_id\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|      loc22| 1000|\n",
      "|      loc31| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").count().orderBy('count', ascending=False).show(5) #in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|      loc22|           28.251|\n",
      "|      loc31|           25.196|\n",
      "|      loc82|           27.355|\n",
      "|      loc90|           23.216|\n",
      "|     loc118|           24.219|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('location_id').agg({'temp_celcius': 'mean'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|max(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|      loc22|               35|\n",
      "|      loc31|               32|\n",
      "|      loc82|               34|\n",
      "|      loc90|               30|\n",
      "|     loc118|               31|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('location_id').agg({'temp_celcius': 'max'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|     loc435|           33.427|\n",
      "|     loc438|           33.371|\n",
      "|     loc112|           33.359|\n",
      "|     loc306|           33.357|\n",
      "|     loc426|           33.348|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('location_id').agg({'temp_celcius': 'mean'}).orderBy('avg(temp_celcius)', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|location_id|avg_temp|\n",
      "+-----------+--------+\n",
      "|     loc435|  33.427|\n",
      "|     loc438|  33.371|\n",
      "|     loc112|  33.359|\n",
      "|     loc306|  33.357|\n",
      "|     loc426|  33.348|\n",
      "+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df1.groupby('location_id').agg(mean('temp_celcius').alias('avg_temp')).orderBy('avg_temp', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling using DataFrames API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49884"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s1 = df1.sample(fraction=0.1, withReplacement=False)\n",
    "df_s1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s2 = df1.sample(fraction=0.001, withReplacement=False)\n",
    "df_s2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|       loc0|29.009708737864077|\n",
      "|       loc1| 28.15909090909091|\n",
      "|      loc10|25.528301886792452|\n",
      "|     loc100|27.128712871287128|\n",
      "|     loc101|25.454545454545453|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_s1.groupBy(\"location_id\").agg({'temp_celcius': 'mean'}).orderBy(\"location_id\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|       loc0|              29.0|\n",
      "|       loc1|26.333333333333332|\n",
      "|      loc10|              27.5|\n",
      "|     loc101|              25.0|\n",
      "|     loc107|              34.0|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_s2.groupBy(\"location_id\").agg({'temp_celcius': 'mean'}).orderBy(\"location_id\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|           29.176|\n",
      "|       loc1|           28.246|\n",
      "|      loc10|           25.337|\n",
      "|     loc100|           27.297|\n",
      "|     loc101|           25.317|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").agg({'temp_celcius': 'mean'}).orderBy(\"location_id\").show(5) #original dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
