{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10950a9",
   "metadata": {},
   "source": [
    "by *canaytore*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf684e7",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b476b",
   "metadata": {},
   "source": [
    "Source: Power Plant -> https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02b268",
   "metadata": {},
   "source": [
    "We're going to use this data to predict how much power a power plant can generate, based on some factors.\n",
    "- The first column is labeled AT, that's for \"ambient temperature\",\n",
    "- The second column is headed with the letter V, and that stands for \"vacuum\", \n",
    "- The third column has AP, which is \"ambient pressure\",\n",
    "- The fourth column is RH for relative \"humidity\",\n",
    "- The fifth and final column is labeled with PE and that's a measure of how much power was generated. We'll be using that as the value that we're trying to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2596d",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6addc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9f6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ea3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df = spark.read.csv(\"/power_plant.csv\", \n",
    "                       header=True, \n",
    "                       inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ff4996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AT: double, V: double, AP: double, RH: double, PE: double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecb8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"AT\",\"V\",\"AP\",\"RH\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7157b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpp_df = vectorAssembler.transform(pp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9690ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vpp_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c1de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"PE\") #we're trying to predict PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c98ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(vpp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40549a87",
   "metadata": {},
   "source": [
    "Let's take a look at some features of that model. For example, linear models have coefficients. So this is a list of four numbers which correspond to the coefficients of the different variables that we were using to build the model. Now another important part of a linear model is the intercept. So if we look at the intercept, that gives us a point where the line crosses the Y axis. So basically, what we've done is we've fit a line to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a636b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.9775, -0.2339, 0.0621, -0.1581])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e91e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454.6092744523414"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d90958",
   "metadata": {},
   "source": [
    "Now one of the important measures of the quality of a linear model is the error. And there are different ways of measuring it. We're going to use the root mean squared error. It's a measure of how much error there is in our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83b6b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.557126016749488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507af04a",
   "metadata": {},
   "source": [
    "But why are we squaring the error? Well, that's because when we make a prediction, sometimes we can overshoot, in which case our error would be positive, but sometimes we might underestimate in which case our error would be negative. If we start adding up positive and negative numbers, they tend to cancel each other out. So the first thing we do is we square the error, then it doesn't matter if it's positive or negative. We're going to have a positive value to work with. We add all those up and take their square root, we get a good measure of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a225ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.save(\"lr.model\") #save the model to be able to work with it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bcbd2",
   "metadata": {},
   "source": [
    "## Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f41f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57244de",
   "metadata": {},
   "source": [
    "Now we're going to consider decision tree regression. Regression is lot like classification, in the sense that we have a number of different algorithms we can use to perform regression and sometimes it helps to experiment with different algorithms to see which works best with your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "398f38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"AT\",\"V\",\"AP\",\"RH\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29877e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpp_df = vectorAssembler.transform(pp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6876b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|   AT|    V|     AP|   RH|    PE|            features|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "|14.96|41.76|1024.07|73.17|463.26|[14.96,41.76,1024...|\n",
      "+-----+-----+-------+-----+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vpp_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9067bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vpp_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e0a84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86bad52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6676"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8251cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b950e2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9568"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7361c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"PE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e040891",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aa0651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2a20d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_evaluator = RegressionEvaluator(labelCol=\"PE\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3887e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.505463629189437"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43460fe7",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de83d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01cfce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"PE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd81f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7252bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_predictions = gbt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1cebfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(labelCol=\"PE\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "544199b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.055289723264364"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "gbt_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00ec3084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.505463629189437"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse #rmse for decision tree regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926be646",
   "metadata": {},
   "source": [
    "*Notes:*\n",
    "- Regression algorithms are designed to make numeric projections. \n",
    "- Gradient-boosted tree regression can sometimes give the best performance, but it may take longer to build models. Like with classification, it helps to experiment with different regression algorithms with your data set. And it also helps to try varying hyperparameters to see if you can tune performance slightly by changing some of those configuration parameters. \n",
    "- In general, it's best to start with linear regression. In real-word examples, linear regression frequently gives usable, high-quality results. Now, if you have a data set that doesn't work well with linear regression, then try decision tree regression. That might give you better results. Now, if you need to get the best performing model possible, and you're willing to spend extra time building the model, then take a look at gradient-boosted tree regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
