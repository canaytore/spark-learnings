{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1703450e",
   "metadata": {},
   "source": [
    "-- Notepad to myself --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b082934",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e1ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6391ec7",
   "metadata": {},
   "source": [
    "Source: Iris dataset -> https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855c624",
   "metadata": {},
   "source": [
    "This data set contains data about three species of irises. The features are measurements of two parts of the flower, the sepal and the petal. There is a length and width measurement for both the sepal and the petal, creating a total of four features. The label in this data set is the name of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154b083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: double (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df = spark.read.csv(\"data/iris.data\", \n",
    "                         inferSchema=True)\n",
    "iris_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92863849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4c912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|    species|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df = iris_df.select(col(\"_c0\").alias(\"sepal_length\"),\n",
    "                        col(\"_c1\").alias(\"sepal_width\"),\n",
    "                        col(\"_c2\").alias(\"petal_length\"),\n",
    "                        col(\"_c3\").alias(\"petal_width\"),\n",
    "                        col(\"_c4\").alias(\"species\"))\n",
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6760648",
   "metadata": {},
   "source": [
    "Now, let's transform this into a vector structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f8b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], \n",
    "                                  outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92dd4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "viris_df = vectorAssembler.transform(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1591a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length=5.1, sepal_width=3.5, petal_length=1.4, petal_width=0.2, species='Iris-setosa', features=DenseVector([5.1, 3.5, 1.4, 0.2]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viris_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3b7ca",
   "metadata": {},
   "source": [
    "So, what we have here is a row that has the four measurements, sepal length, width, petal length, and petal width, and then we have also the species, as well as the features, and that feature has the vector with the four measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e80c",
   "metadata": {},
   "source": [
    "Now, the last piece of preprocessing we want to do is we want to convert the label name, which is the species name, into a numeric value, and here's where we're going to use that transformation called string indexer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745d79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62851516",
   "metadata": {},
   "outputs": [],
   "source": [
    "iviris_df = indexer.fit(viris_df).transform(viris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b2b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species    |features         |label|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
      "|5.1         |3.5        |1.4         |0.2        |Iris-setosa|[5.1,3.5,1.4,0.2]|0.0  |\n",
      "|4.9         |3.0        |1.4         |0.2        |Iris-setosa|[4.9,3.0,1.4,0.2]|0.0  |\n",
      "|4.7         |3.2        |1.3         |0.2        |Iris-setosa|[4.7,3.2,1.3,0.2]|0.0  |\n",
      "|4.6         |3.1        |1.5         |0.2        |Iris-setosa|[4.6,3.1,1.5,0.2]|0.0  |\n",
      "|5.0         |3.6        |1.4         |0.2        |Iris-setosa|[5.0,3.6,1.4,0.2]|0.0  |\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iviris_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38193b40",
   "metadata": {},
   "source": [
    "So, what we have is our four measurements, sepal length, sepal width, petal length, petal width, we have species listed, we have the feature vector, and then a little wrapping around the screen is the word \"label\", and label has a value of 0.0. That's because the species, in this case iris-setosa, has been mapped to an index value of zero. So, this concludes our preprocessing step, and now we're ready to apply classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336c991",
   "metadata": {},
   "source": [
    "## Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6dd757",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1348f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator #to evaluate the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4d834",
   "metadata": {},
   "source": [
    "We have split our iris data set into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263f8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = iviris_df.randomSplit([0.6, 0.4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a489414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82400208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e2a2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d8450ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iviris_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2edb4",
   "metadata": {},
   "source": [
    "The model type is multinomial, and that just means that there are more than two different classes that we're going to be working with. In our case, there are three different types of irises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a0dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(modelType=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888ac7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbmodel = nb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779d7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = nbmodel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae771e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length=4.3, sepal_width=3.0, petal_length=1.1, petal_width=0.1, species='Iris-setosa', features=DenseVector([4.3, 3.0, 1.1, 0.1]), label=0.0, rawPrediction=DenseVector([-9.9894, -11.3476, -11.902]), probability=DenseVector([0.7118, 0.183, 0.1051]), prediction=0.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b148b43",
   "metadata": {},
   "source": [
    "We eventually have some raw predictions and a probability dense vector, which came from the model, and then we have the final column called \"prediction.\" Now in this case, the prediction is zero. Zero is an index value into one of the species. Zero is the index for the iris-setosa, so this prediction is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83f675",
   "metadata": {},
   "source": [
    "Now, looking at one example does not tell us how well the model behaves overall, so let's do a more thorough evaluation. Let's create an evaluator, and the metric that we're trying to measure is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f03b6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d55c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807692307692307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbaccuarcy = evaluator.evaluate(predictions_df)\n",
    "nbaccuarcy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda704b",
   "metadata": {},
   "source": [
    "### Multi-layer perception classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f211b",
   "metadata": {},
   "source": [
    "Now we're going to work with a multi-layer perceptron, which is a type of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4a86f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5657d9",
   "metadata": {},
   "source": [
    "The way a multi-layer perceptron classifier works is that we have, as the name implies, multiple levels of neurons. Now in all cases, **the first layer has the same number of nodes as there are inputs**. So for us we have four measures so our first layer will be four. And **the last element should have the same number of neurons as there are types of outputs**. Now in our case there's three types of iris species. Finally we want to have layers in between, and the layers in between will help the multi-layer perceptron learn how to classify correctly. So I'm going to insert two rows of five neurons each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8956d",
   "metadata": {},
   "source": [
    "So we are going to have a four layer multi-layer perceptron. First layer will have four neurons, the middle two layers will have five neurons each, and then the output layer will have three neurons. One for each kind of iris species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efc828cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [4, 5, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40074e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultilayerPerceptronClassifier(layers=layers, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd56ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = mlp.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a337b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predictions = mlp_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "891dc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cca9d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f37601",
   "metadata": {},
   "source": [
    "### Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1535cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67794284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4e23405",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f1b9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de85efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c0bdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423076923076923"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
    "dt_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfc335",
   "metadata": {},
   "source": [
    "*Notes:*\n",
    "- The multilayer perceptron worked well, but required us to make some configuration decisions, with regards to how to structure the neural net.\n",
    "- Decision trees worked as well as the multilayer perceptron, but didn't require us to make any configuration decisions.\n",
    "- In general, when working with classification algorithms it's helpful to experiment with a number of different algorithms and a number of different configurations, if that's required by the algorithm. \n",
    "- Naive Bayes can work well in some cases. For example, if the attributes in your data set are what is known as independent of each other. That is, they don't tightly correlate with each other. \n",
    "- In other cases, when you have non-linear relationships between data elements, the multilayer perceptron is a good option. \n",
    "- Decision trees are a good option in many cases and it's worth starting with decision trees and then trying other classification algorithms from there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
